{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEP24-MLB: Regression and demand forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is is used for making predictions about real-world quantities (continuous values). For example, we want to predict the effects of changes in the price on the sales volume. Another example is studying how the sales volume of a given restaurant is affected by the weather? In the tasks when the variable to be predicted is coninuous, we use regression techniques. In this tutorial, we will focus on linear regression. We will start by importing the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the example from the slides. We will start by estimating the parameters as we did in the slides and compare the estimated prameters with those that are estimated using the `LinearRegression` class from Scikit Learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Use the formula from the slides to compute the paramters of the linear regression model\n",
    "w0 , w1 (in the slides) represent the intercept and coef, respectively\n",
    "'''\n",
    "x = [1, 2, 2.5, 2, 4, 4, 4, 4.5, 4.7, 5, 5, 6, 6, 7]\n",
    "y = [7, 4, 9, 8, 9, 8, 9, 7, 11, 11, 10, 13, 14, 13]\n",
    "x_mean = np.mean(x)\n",
    "y_mean = np.mean(y)\n",
    "\n",
    "x_diff = x - x_mean\n",
    "y_diff = y - y_mean\n",
    "\n",
    "coef = sum(x_diff * y_diff) / sum(x_diff ** 2)\n",
    "intercept = y_mean - coef * x_mean\n",
    "intercept , coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Use the `LinearRegression` class to estimate the parameters and compare the results\n",
    "'''\n",
    "xc = np.array(x)\n",
    "yc = np.array(y)\n",
    "lrmdl = LinearRegression()\n",
    "lrmdl.fit(xc.reshape(len(xc),1), yc.reshape(len(yc),1))\n",
    "# Print the intercept and the coifficient of the model\n",
    "print('\\n\\nUsing the scikit learn package:')\n",
    "print( \"Coefficients:\", lrmdl.coef_[0][0])\n",
    "print( \"Intercept:\", lrmdl.intercept_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real example\n",
    "Let us apply the cioncepts on real-world data such as the [diabetes data](https://github.com/semerj/NHANES-diabetes/tree/master/data/diabetes_data_train.csv). We start by downloading the data, uploading it on Google Colab and reading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.read_csv('sample_data/diabetes_data_train.csv')\n",
    "df_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: the column status represents the classes of the records, check how many classes do we have\n",
    "'''\n",
    "df_diabetes.status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: check the correlation between the attributes to see if there are two attributes that are highly correlated\n",
    "We will start by removing the records with null values\n",
    "'''\n",
    "df_n = df_diabetes.dropna()\n",
    "corr_mat = df_n.corr()\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: use a scatter plot to plot the attributes that are highly correlated \n",
    "'''\n",
    "font_size = 16               # you can use the size that would be readable easily\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "x = df_n.BMXWAIST\n",
    "y = df_n.BMXWT\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these two feature in the following exercises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: fit a linear regression model on the data \n",
    "'''\n",
    "feat1 = 'BMXWAIST'\n",
    "feat2 = 'BMXWT'\n",
    "\n",
    "x = np.array(df_n[feat1]).reshape(-1,1)\n",
    "y = np.array(df_n[feat2]).reshape(-1,1)\n",
    "mdl = LinearRegression()\n",
    "mdl.fit(x, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "plt.plot(x,y, \"o\");\n",
    "te = np.arange(min(x),max(x)+4).reshape(-1,1)\n",
    "te_hat = mdl.predict(te)\n",
    "plt.plot(te, te_hat, 'r')\n",
    "\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "\n",
    "y_hat = mdl.predict(x)\n",
    "MAE = round(np.mean(np.abs(y - y_hat)),2)\n",
    "\n",
    "ax.text(125, 70, \"MAE = \" + str(MAE), style='italic',\n",
    "       bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})\n",
    "# plt.title(\"MAE = \" + str(MAE))\n",
    "plt.savefig('linear.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: display the intercept and the coefficient of the linear model\n",
    "'''\n",
    "round(mdl.intercept_[0], 2), round(mdl.coef_[0][0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: modify the intercept and the coefficient slightley and plot the new model with the old one\n",
    "'''\n",
    "# We modify the intercept from -28.7 to -27 \n",
    "# and the coefficient from 1.3 to 1.2\n",
    "mdl.intercept_[0] = -27\n",
    "mdl.coef_[0][0] = 1.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "plt.plot(x,y, \"o\");\n",
    "te = np.arange(min(x),max(x)+4).reshape(-1,1)\n",
    "te_hat2 = mdl.predict(te)\n",
    "plt.plot(te, te_hat, 'r')      # use the first model for prediction \n",
    "plt.plot(te, te_hat2, 'g')      # use the modified model for prediction \n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "y_hat2 = mdl.predict(x)\n",
    "MAE2 = round(np.mean(np.abs(y - y_hat2)),2)\n",
    "\n",
    "ax.text(125, 70, \"MAE = \" + str(MAE), style='italic',\n",
    "       bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})\n",
    "\n",
    "ax.text(125, 50, \"MAE = \" + str(MAE2), style='italic',\n",
    "       bbox={'facecolor': 'green', 'alpha': 0.5, 'pad': 10})\n",
    "# plt.savefig('linear.pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "TODO: fit a polynomail regression model with degree 3 on the data \n",
    "Use the numpy model: np.poly1d(np.polyfit(x, y, 3))\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "x1 = np.array(df_n[\"BMXWAIST\"])\n",
    "y1 = np.array(df_n[\"BMXWT\"])\n",
    "te = np.arange(min(x1),max(x1))\n",
    "ploy_mdl_3 = np.poly1d(np.polyfit(x1, y1, 3))\n",
    "\n",
    "\n",
    "plt.plot(x1, y1, \"o\");\n",
    "plt.plot(te, ploy_mdl_3(te), 'k')\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "\n",
    "y_hat = ploy_mdl_3(x1)\n",
    "MAE = round(np.mean(np.abs(y1 - y_hat)),2)\n",
    "\n",
    "ax.text(125, 55, \"MAE = \" + str(MAE), style='italic',\n",
    "       bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})\n",
    "# plt.savefig('poly1.pdf', bbox_inches = 'tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: fit a polynomail regression model with degree 7 on the data  \n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "x1 = np.array(df_n[\"BMXWAIST\"])\n",
    "y1 = np.array(df_n[\"BMXWT\"])\n",
    "te = np.arange(min(x1),max(x1))\n",
    "ploy_mdl_7 = np.poly1d(np.polyfit(x1, y1, 7))\n",
    "\n",
    "\n",
    "plt.plot(x1, y1, \"o\");\n",
    "plt.plot(te, ploy_mdl_7(te), 'k')\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "\n",
    "y_hat = ploy_mdl_7(x1)\n",
    "MAE = round(np.mean(np.abs(y1 - y_hat)),2)\n",
    "\n",
    "\n",
    "ax.text(125, 55, \"MAE = \" + str(MAE), style='italic',\n",
    "       bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})\n",
    "# plt.savefig('poly1.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same exercise on a sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "sample = df_n.sample(n = 20)\n",
    "x_sam = sample[\"BMXWAIST\"]\n",
    "y_sam = sample[\"BMXWT\"]\n",
    "ax.scatter(x_sam, y_sam)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: fit the three models using the sample this time\n",
    "'''\n",
    "x_sam = np.array(sample[\"BMXWAIST\"]).reshape(-1, 1)\n",
    "y_sam = np.array(sample[\"BMXWT\"]).reshape(-1, 1)\n",
    "\n",
    "mdl_sam = LinearRegression()\n",
    "mdl_sam.fit(x_sam, y_sam)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "plt.plot(x_sam, y_sam, \"o\");\n",
    "te = np.arange(min(x_sam),max(x_sam)+4).reshape(-1,1)\n",
    "te_hat = mdl_sam.predict(te)\n",
    "plt.plot(te, te_hat, 'r')\n",
    "\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "\n",
    "y_hat = mdl_sam.predict(x_sam)\n",
    "# compute the error on the training values\n",
    "MAE = round(np.mean(np.abs(y_sam - y_hat)),2)     \n",
    "\n",
    "ax.text(105, 55, \"MAE = \" + str(MAE), style='italic',\n",
    "       bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We fit a polynomail regression model with degree 3 on the sample data \n",
    "You can use similar code as earlier to fit a polynomail regression model with degree 7\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "x_sam1 = np.array(sample[\"BMXWAIST\"])\n",
    "y_sam1 = np.array(sample[\"BMXWT\"])\n",
    "\n",
    "te = np.arange(min(x_sam1)-3, max(x_sam1)+3)\n",
    "ploy_mdl_sam_3 = np.poly1d(np.polyfit(x_sam1, y_sam1, 3))\n",
    "\n",
    "\n",
    "plt.plot(x_sam1, y_sam1, \"o\");\n",
    "plt.plot(te, ploy_mdl_sam_3(te), 'k')\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "\n",
    "y_hat = ploy_mdl_sam_3(x_sam1)\n",
    "MAE = round(np.mean(np.abs(y_sam1 - y_hat)),2)\n",
    "\n",
    "ax.text(105, 55, \"MAE = \" + str(MAE), style='italic',\n",
    "       bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Let's split the sample data into two subsets train, test\n",
    "Documentation can be found at \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_sam, y_sam, test_size=0.25)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: fit the three models on the train set and use them to predict the values in the test set\n",
    "Compute the Mean Absolute Error on the test set\n",
    "\n",
    "We will perform the linear regression and you can do the polynomial regression as an exercise\n",
    "'''\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "mdl_t = LinearRegression()\n",
    "mdl_t.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "plt.plot(X_train, y_train, \"o\");\n",
    "te = np.arange(min(X_train) - 10, max(X_train)+10).reshape(-1,1)\n",
    "te_hat = mdl_t.predict(te)\n",
    "plt.plot(te, te_hat, 'b')\n",
    "\n",
    "plt.xlabel(\"Waist Circumference (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "\n",
    "y_hat = mdl_t.predict(X_test)\n",
    "plt.plot(X_test, y_hat, 'og')\n",
    "plt.plot(X_test, y_test, 'or')\n",
    "\n",
    "# Plot a red vertical line between the actual test point and the predicted value\n",
    "for i in range(len(X_test)):\n",
    "    p = X_test[i]\n",
    "    p_st_end = np.array([y_test[i], y_hat[i]])\n",
    "    plt.plot(np.array([p, p]), p_st_end, '-r')\n",
    "\n",
    "# compute the error on the training values\n",
    "MAE = round(np.mean(np.abs(y_test - y_hat)),2)     \n",
    "\n",
    "ax.text(105, 55, \"MAE = \" + str(MAE), style='italic',\n",
    "       bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Training Data', \n",
    "                         markerfacecolor='b', markersize = 8),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Testing Data (Actual)',\n",
    "                          markerfacecolor='r', markersize = 8),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Testing Data (Predicted)',\n",
    "                          markerfacecolor='g', markersize = 8),\n",
    "                   Line2D([0], [0], lw = 2, color='r', label='Error')]\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "'''\n",
    "The red vertical lines represent the difference between the actual values and the predicted values\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Forecasting\n",
    "\n",
    "We will start with the example from the slides. \n",
    "\n",
    "#### 1. Na√Øve Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The predicted value at time t_n is the value at time t_n-1\n",
    "'''\n",
    "data = [122, 91, 100, 77, 115, 58, 75, 128, 111, 88]\n",
    "predictionsNF = {}\n",
    "for item in range(1,len(data)+1):    \n",
    "    predNF = data[item - 1]\n",
    "    predictionsNF.update({item + 1:predNF})\n",
    "predictionsNF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Simple Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The predicted value at time t_n is the average of the values t_0, t_1, ..., t_n-1\n",
    "'''\n",
    "predictionsSA = {}\n",
    "for item in range(len(data)+1):\n",
    "    if (data[0:item]):\n",
    "        predSA = round(np.mean(data[0:item]), 2)\n",
    "        predictionsSA.update({item + 1:int(round(predSA,0))})\n",
    "predictionsSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Moving Average (MA) -- k = 3\n",
    "\n",
    "The predicted value at time t_n is the average of the values t_n-3, t_n-2, t_n-1\n",
    "'''\n",
    "k = 3\n",
    "predictionsMA = {}\n",
    "for item in range(len(data)-k+1):\n",
    "    predMA = round(np.mean(data[item:item+k]), 2)\n",
    "    predictionsMA.update({item + k + 1:int(round(predMA,0))})\n",
    "predictionsMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Weighted Moving Average (WMA) -- k = 3\n",
    "\n",
    "The predicted value at time t_n is: c_3 * t_n-3 + c_2 * t_n-2 + c_1 * t_n-1\n",
    "We should have c_3 + c_2 + c_1 = 1\n",
    "'''\n",
    "predictionsWMA = {}\n",
    "k = 3\n",
    "w = np.array([0.2,0.3,0.5])\n",
    "for item in range(len(data)-k+1):\n",
    "    predWMA = np.sum(np.array(data[item:item+k]) * w)\n",
    "    predictionsWMA.update({item + k + 1 : int(round(predWMA))})\n",
    "predictionsWMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Exponential Smoothing (ES -- alpha = 0.5) \n",
    "\n",
    "The predicted value at time t_n is the sum of the history multiplied by (1-alpha) \n",
    "and the most recent value multiplied by alpha\n",
    "'''\n",
    "history = 0.0\n",
    "alpha = 0.5\n",
    "predictionsES = {}\n",
    "predES = 0.0\n",
    "for item in range(2,len(data)+1):\n",
    "    if (not(predictionsES)):\n",
    "        p1 = data[item-2] * (1.0 - alpha)\n",
    "        p2 = data[item - 1] * alpha\n",
    "        predES = p1 + p2\n",
    "    else:\n",
    "        history = predictionsES[item]\n",
    "        p1 = history * (1 - alpha)\n",
    "        p2 = data[item - 1] * alpha\n",
    "        predES = p1 + p2\n",
    "    predictionsES.update({item+1: int(round(predES))})\n",
    "predictionsES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We learn a linear regression by estimating its parameters from the data.\n",
    "We can use the learned model for predicting the future values\n",
    "'''\n",
    "xr = range(len(data))\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "plt.plot(xr, data)\n",
    "x = np.array(xr).reshape(-1,1)\n",
    "y = np.array(data).reshape(-1,1)\n",
    "mdl = LinearRegression()\n",
    "mdl.fit(x, y)\n",
    "xm = np.arange(min(x)-1,max(x)+1).reshape(-1,1)\n",
    "ym = mdl.predict(xm)\n",
    "plt.plot(xm, ym)\n",
    "\n",
    "test = np.array([11]).reshape(-1,1)\n",
    "test_hat = mdl.predict(test)\n",
    "print(test, ':', int(round(test_hat[0,0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- we read a time series from csv file, we use the [oil price](https://www.kaggle.com/c/store-sales-time-series-forecasting/data) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oil = pd.read_csv('sample_data/oil.csv', header = 0,\n",
    "                 quotechar='\"',sep=\",\",\n",
    "                 na_values = ['na', '-', '.', ''], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- We take a look at the data by plotting the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots()\n",
    "start = 0\n",
    "limit = len(df_oil)\n",
    "end = start + limit - 1\n",
    "ax.plot(df_oil.date[start:end], df_oil.dcoilwtico[start:end], '-')\n",
    "\n",
    "x = [df_oil.date.iloc[start], df_oil.date.iloc[start + math.floor(limit / 4)], \\\n",
    "     df_oil.date.iloc[start + math.floor(limit / 2)], df_oil.date.iloc[start + math.floor(3 * limit / 4)], \\\n",
    "     df_oil.date.iloc[end]]\n",
    "\n",
    "ax.set_xticks(x)\n",
    "plt.xticks(rotation = 45)\n",
    "ax.set(xlabel='Date', ylabel='Oil Price')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- We cannot see a lot of details, let's consider a smaller period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots()\n",
    "start = 300\n",
    "limit = 300\n",
    "end = start + limit - 1\n",
    "ax.plot(df_oil.date[start:end], df_oil.dcoilwtico[start:end], '-')\n",
    "\n",
    "\n",
    "x = [df_oil.date.iloc[start], df_oil.date.iloc[start + math.floor(limit / 4)], \\\n",
    "     df_oil.date.iloc[start + math.floor(limit / 2)], df_oil.date.iloc[start + math.floor(3 * limit / 4)], \\\n",
    "     df_oil.date.iloc[end]]\n",
    "\n",
    "ax.set_xticks(x)\n",
    "plt.xticks(rotation = 45)\n",
    "ax.set(xlabel='Date', ylabel='Oil Price')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- We fill the missing values and use moving average to smooth the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, fill the missing values with the closest existing value.\n",
    "df_oil_new = df_oil.copy()\n",
    "\n",
    "while df_oil_new[\"dcoilwtico\"].isnull().any():\n",
    "    df_oil_new = df_oil_new.fillna(method='pad', limit=1)\n",
    "    df_oil_new = df_oil_new.fillna(method='bfill', limit=1)\n",
    "\n",
    "ma_win_size = 50\n",
    "df_oil_new['dcoilwtico'] = df_oil_new['dcoilwtico'].rolling(window = ma_win_size).mean()\n",
    "\n",
    "start = ma_win_size + 10\n",
    "limit = len(df_oil_new) - ma_win_size\n",
    "end = start + limit - 11\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df_oil_new.date[start:end], df_oil_new.dcoilwtico[start:end], '-')\n",
    "x = [df_oil_new.date.iloc[start], df_oil_new.date.iloc[start + math.floor(limit / 4)], \\\n",
    "     df_oil_new.date.iloc[start + math.floor(limit / 2)], df_oil_new.date.iloc[start + math.floor(3 * limit / 4)], \\\n",
    "     df_oil_new.date.iloc[end]]\n",
    "ax.set_xticks(x)\n",
    "plt.xticks(rotation = 45)\n",
    "ax.set(xlabel='Date', ylabel='Oil Price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read the data again\n",
    "df_oil_FC = pd.read_csv('sample_data/oil.csv', header = 0,\n",
    "                 quotechar='\"',sep=\",\",\n",
    "                 na_values = ['na', '-', '.', ''], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, in demand forecasting, we deal with time series, we remove the last two weeks of the data and store it as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while df_oil_FC[\"dcoilwtico\"].isnull().any():\n",
    "    df_oil_FC = df_oil_FC.fillna(method='pad', limit=1)\n",
    "    df_oil_FC = df_oil_FC.fillna(method='bfill', limit=1)\n",
    "idx = df_oil_FC.index[df_oil_FC.date == '2017-08-16'].tolist()\n",
    "train = df_oil_FC.iloc[0:idx[0]]\n",
    "test = df_oil_FC.iloc[idx[0]:len(df_oil_FC)]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform demand forecasting using moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "start = len(train) - k\n",
    "end = len(train)\n",
    "new_list = train.dcoilwtico.iloc[start:end].tolist()\n",
    "# last = new_list.index\n",
    "\n",
    "for item in test.date:\n",
    "    windowMA = round(np.mean(new_list[-k:]), 2)\n",
    "    new_list.append(windowMA)\n",
    "new_list[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the actual price for the test data\n",
    "test.dcoilwtico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the means squared error\n",
    "t = len(test)\n",
    "MSE = np.mean((new_list[-t:] - test.dcoilwtico)**2)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform demand forecasting using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train the model using the last 11 samples from the time series\n",
    "\n",
    "train = train[-11:]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "offset = math.floor(len(train) / 2)\n",
    "train['x'] = train.index - offset\n",
    "\n",
    "xc = np.array(train.x)\n",
    "yc = np.array(train.dcoilwtico)\n",
    "\n",
    "myLR = LinearRegression()\n",
    "myLR.fit(xc.reshape(len(xc),1), yc.reshape(len(yc),1))\n",
    "# Print the intercept and the coifficient of the model\n",
    "a0 = myLR.intercept_[0]\n",
    "a1 = myLR.coef_[0][0]\n",
    "new_list = list()\n",
    "xi = np.max(train.x) + 1\n",
    "for item in test.date:\n",
    "    yi = a0 + a1 * xi \n",
    "    new_list.append(yi)\n",
    "    xi += 1\n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "MAE = np.mean(abs(new_list - test.dcoilwtico)) # computing the mean squared error\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "MSE = np.mean((new_list - test.dcoilwtico)**2) # computing the mean squared error\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of squared error\n",
    "SSE = np.sum((new_list - test.dcoilwtico)**2) # computing the sum squared error\n",
    "SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-Square\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(test.dcoilwtico, new_list)\n",
    "r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
